{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6863a0",
   "metadata": {},
   "source": [
    "# **Introduction to SmoalAgents**\n",
    "\n",
    "![](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/smolagents/thumbnail.jpg)\n",
    "\n",
    "Welcome to this module, where you will learn **how to build effective agents** using the smolagents library, which provides a lightweight framework for creating capable AI agents. \n",
    "\n",
    "We’ll explore critical agent types, including code agents designed for software development tasks, tool calling agents for creating modular, function-driven workflows, and retrieval agents that access and synthesize information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e59591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f07933e5be14fa1a99339019003286f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ba6f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭──────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Search for the best music recommendations for a party at the Wayne's mansion.</span>                                   <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ──────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mSearch for the best music recommendations for a party at the Wayne's mansion.\u001b[0m                                   \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating model output:</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Client Error: Payment Required for url: </span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> (Request ID: </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Root</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">-680d3961-3a0477dc35d9fb312a616839;</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">979fb1e1-0ff0-44ca-bd67-4cb54ca39817</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 2</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> more monthly </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">included credits.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mError in generating model output:\u001b[0m\n",
       "\u001b[1;36m402\u001b[0m\u001b[1;31m Client Error: Payment Required for url: \u001b[0m\n",
       "\u001b[4;94mhttps://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: \u001b[0m\n",
       "\u001b[1;33mRoot\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;31m-680d3961-3a0477dc35d9fb312a616839;\u001b[0m\u001b[93m979fb1e1-0ff0-44ca-bd67-4cb54ca39817\u001b[0m\u001b[1;31m)\u001b[0m\n",
       "\n",
       "\u001b[1;31mYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 2\u001b[0m\u001b[1;36m0x\u001b[0m\u001b[1;31m more monthly \u001b[0m\n",
       "\u001b[1;31mincluded credits.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 0.66 seconds]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 0.66 seconds]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AgentGenerationError",
     "evalue": "Error in generating model output:\n402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-680d3961-3a0477dc35d9fb312a616839;979fb1e1-0ff0-44ca-bd67-4cb54ca39817)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/smolagents/agents.py:1266\u001b[39m, in \u001b[36mCodeAgent.step\u001b[39m\u001b[34m(self, memory_step)\u001b[39m\n\u001b[32m   1265\u001b[39m additional_args = {\u001b[33m\"\u001b[39m\u001b[33mgrammar\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.grammar} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.grammar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m chat_message: ChatMessage = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1267\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m<end_code>\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mObservation:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCalling tools:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1271\u001b[39m memory_step.model_output_message = chat_message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/smolagents/models.py:1090\u001b[39m, in \u001b[36mInferenceClientModel.__call__\u001b[39m\u001b[34m(self, messages, stop_sequences, grammar, tools_to_call_from, **kwargs)\u001b[39m\n\u001b[32m   1081\u001b[39m completion_kwargs = \u001b[38;5;28mself\u001b[39m._prepare_completion_kwargs(\n\u001b[32m   1082\u001b[39m     messages=messages,\n\u001b[32m   1083\u001b[39m     stop_sequences=stop_sequences,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1088\u001b[39m     **kwargs,\n\u001b[32m   1089\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1090\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28mself\u001b[39m.last_input_token_count = response.usage.prompt_tokens\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:992\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    985\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    986\u001b[39m     inputs=messages,\n\u001b[32m    987\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    990\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    991\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m992\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:357\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:482\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-680d3961-3a0477dc35d9fb312a616839;979fb1e1-0ff0-44ca-bd67-4cb54ca39817)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAgentGenerationError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmolagents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CodeAgent, DuckDuckGoSearchTool, HfApiModel\n\u001b[32m      3\u001b[39m agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=HfApiModel())\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSearch for the best music recommendations for a party at the Wayne\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms mansion.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/smolagents/agents.py:341\u001b[39m, in \u001b[36mMultiStepAgent.run\u001b[39m\u001b[34m(self, task, stream, reset, images, additional_args, max_steps)\u001b[39m\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run(task=\u001b[38;5;28mself\u001b[39m.task, max_steps=max_steps, images=images)\n\u001b[32m    340\u001b[39m \u001b[38;5;66;03m# Outputs are returned only at the end. We only look at the last step.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m].final_answer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/smolagents/agents.py:365\u001b[39m, in \u001b[36mMultiStepAgent._run\u001b[39m\u001b[34m(self, task, max_steps, images)\u001b[39m\n\u001b[32m    362\u001b[39m     final_answer = \u001b[38;5;28mself\u001b[39m._execute_step(task, action_step)\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AgentGenerationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    364\u001b[39m     \u001b[38;5;66;03m# Agent generation errors are not caused by a Model error but an implementation error: so we should raise them and exit.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AgentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# Other AgentError types are caused by the Model, so we should log them and iterate.\u001b[39;00m\n\u001b[32m    368\u001b[39m     action_step.error = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/smolagents/agents.py:362\u001b[39m, in \u001b[36mMultiStepAgent._run\u001b[39m\u001b[34m(self, task, max_steps, images)\u001b[39m\n\u001b[32m    360\u001b[39m action_step = \u001b[38;5;28mself\u001b[39m._create_action_step(step_start_time, images)\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     final_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AgentGenerationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    364\u001b[39m     \u001b[38;5;66;03m# Agent generation errors are not caused by a Model error but an implementation error: so we should raise them and exit.\u001b[39;00m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/smolagents/agents.py:385\u001b[39m, in \u001b[36mMultiStepAgent._execute_step\u001b[39m\u001b[34m(self, task, memory_step)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: \u001b[38;5;28mstr\u001b[39m, memory_step: ActionStep) -> Union[\u001b[38;5;28;01mNone\u001b[39;00m, Any]:\n\u001b[32m    384\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger.log_rule(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.step_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, level=LogLevel.INFO)\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     final_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m final_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.final_answer_checks:\n\u001b[32m    387\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_final_answer(final_answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hugging_face_ai_Agent/agent_venv/lib/python3.12/site-packages/smolagents/agents.py:1282\u001b[39m, in \u001b[36mCodeAgent.step\u001b[39m\u001b[34m(self, memory_step)\u001b[39m\n\u001b[32m   1280\u001b[39m     memory_step.model_output = model_output\n\u001b[32m   1281\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AgentGenerationError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError in generating model output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.logger) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1284\u001b[39m \u001b[38;5;28mself\u001b[39m.logger.log_markdown(\n\u001b[32m   1285\u001b[39m     content=model_output,\n\u001b[32m   1286\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mOutput message of the LLM:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1287\u001b[39m     level=LogLevel.DEBUG,\n\u001b[32m   1288\u001b[39m )\n\u001b[32m   1290\u001b[39m \u001b[38;5;66;03m# Parse\u001b[39;00m\n",
      "\u001b[31mAgentGenerationError\u001b[39m: Error in generating model output:\n402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-680d3961-3a0477dc35d9fb312a616839;979fb1e1-0ff0-44ca-bd67-4cb54ca39817)\n\nYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits."
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\n",
    "\n",
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=HfApiModel())\n",
    "\n",
    "agent.run(\"Search for the best music recommendations for a party at the Wayne's mansion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, tool, HfApiModel\n",
    "\n",
    "# Tool to suggest a menu based on the occasion\n",
    "@tool\n",
    "def suggest_menu(occasion: str) -> str:\n",
    "    \"\"\"\n",
    "    Suggests a menu based on the occasion.\n",
    "    Args:\n",
    "        occasion (str): The type of occasion for the party. Allowed values are:\n",
    "                        - \"casual\": Menu for casual party.\n",
    "                        - \"formal\": Menu for formal party.\n",
    "                        - \"superhero\": Menu for superhero party.\n",
    "                        - \"custom\": Custom menu.\n",
    "    \"\"\"\n",
    "    if occasion == \"casual\":\n",
    "        return \"Pizza, snacks, and drinks.\"\n",
    "    elif occasion == \"formal\":\n",
    "        return \"3-course dinner with wine and dessert.\"\n",
    "    elif occasion == \"superhero\":\n",
    "        return \"Buffet with high-energy and healthy food.\"\n",
    "    else:\n",
    "        return \"Custom menu for the butler.\"\n",
    "\n",
    "# Alfred, the butler, preparing the menu for the party\n",
    "agent = CodeAgent(tools=[suggest_menu], model=HfApiModel())\n",
    "\n",
    "# Preparing the menu for the party\n",
    "agent.run(\"Prepare a formal menu for the party.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "agent = CodeAgent(tools=[], model=HfApiModel(), additional_authorized_imports=['datetime'])\n",
    "\n",
    "agent.run(\n",
    "    \"\"\"\n",
    "    Alfred needs to prepare for the party. Here are the tasks:\n",
    "    1. Prepare the drinks - 30 minutes\n",
    "    2. Decorate the mansion - 60 minutes\n",
    "    3. Set up the menu - 45 minutes\n",
    "    4. Prepare the music and playlist - 45 minutes\n",
    "\n",
    "    If we start right now, at what time will the party be ready?\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.push_to_hub('dhavalantala/AlfredAgent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb5fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80411d-e3c6-4aea-905a-54701cb3af49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629226e4-59cd-47bb-90f4-2f4b6f61f823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
