{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6049888b",
   "metadata": {},
   "source": [
    "## **Understanding AI agents through the Thought-Action-Observation Cycle**\n",
    "\n",
    "![](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/whiteboard-check-3.jpg)\n",
    "\n",
    "In the previous sections, we learned:\n",
    "\n",
    "- **How tools are made available to the agent in the system prompt**.\n",
    "- **How AI agents are systems that can ‘reason’, plan, and interact with their environment**.\n",
    "\n",
    "In this section, **we'll explore the complete AI Agent workflow**, a cycle we defined as Thought-Action-Observation. \n",
    "\n",
    "And then, we'll dive deeper on each of these steps. \n",
    "\n",
    "### **The core Components**\n",
    "\n",
    "Agent work in a continuous cycle of: **thinking(Thought) → acting (Act) and observing(observe). \n",
    "\n",
    "Let's break down these actions together:\n",
    "1. **Thought**: The LLM part of the Agent decides what the next step should be. \n",
    "2. **Action**: The agent takes an action, by calling the tools with the associated arguments. \n",
    "3. **Observation**: The model reflects on the response from the tool. \n",
    "\n",
    "### **The Thought-Action-Observation Cycle**\n",
    "\n",
    "The three components work together in a continuous loop. To use an analogy from programming, the agent uses a **while loop**: the loop continues untill the object of the agent has been fulfilled. \n",
    "\n",
    "Visually, it looks like this: \n",
    "\n",
    "<center><img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/AgentCycle.gif\"></center>\n",
    "\n",
    "In many Agent framworks, **the rules and guidlines are embedded directly into the system prompt**, ensuring that every sysle adheres to a defined logic. \n",
    "\n",
    "In a simplified version, out system prompt may look like this:\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/system_prompt_cycle.png\">\n",
    "\n",
    "We see here that in the System Message we defined:\n",
    "- The *Agent's behavior*.\n",
    "- The Tools our Agent has access to*, as we described in the previous section.\n",
    "- The *Thought-Action-Observation Cycle*, that we bake into LLM Instructions. \n",
    "\n",
    "Let's take a small example to understand the process before going deeper into each step of the process. \n",
    "\n",
    "### **Alfred, the weather Agent**\n",
    "\n",
    "We created Alfred, the Weather Agent. \n",
    "\n",
    "A user asks ALfred: \"What's the current weather in New Your?\"\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/alfred-agent.jpg\">\n",
    "\n",
    "Alfred's job is to answer this query using a weather API tool. \n",
    "\n",
    "Here's how the cycle unfolds:\n",
    "\n",
    "**Thought**\n",
    "\n",
    "**Internal Reasoning**\n",
    "\n",
    "Upon receiving the query, Alfred's internal dialogue might be: \n",
    "\n",
    "\"*The user needs current weather information for New York. I have access to a tool that fetches weather data. First, I need to call the weather API to get up-to-date details.*\"\n",
    "\n",
    "The step shows the agent breaking the problem into steps: first, gathering the necessary data. \n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/alfred-agent-1.jpg\">\n",
    "\n",
    "**Action** \n",
    "\n",
    "**Tool Usage**:\n",
    "\n",
    "Based on its reasoning and the fact that Alfred known about a `get_weather` tool, Alfred prepares a JSON-formatted command that calls the weather API tool. For example, its first action could be:\n",
    "\n",
    "Thought: I need to check the current weather for New York. \n",
    "\n",
    "```Python\n",
    "   {\n",
    "     \"action\": \"get_weather\",\n",
    "     \"action_input\": {\n",
    "       \"location\": \"New York\"\n",
    "     }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "Here, the action clearly specifies which tool to call(e.g., `get_weather`) and what parameter to pass (the \"location\":\"New York\").\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/alfred-agent-2.jpg\">\n",
    "\n",
    "**Observation** \n",
    "\n",
    "**Feedback from the Environment** \n",
    "\n",
    "After the tool call, Alfred receives an observation. This might be the raw wether data from the API such as: \n",
    "\n",
    "\"*`Current weather in New York: partly cloudy, 15°C, 60% humidity.`*\"\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/alfred-agent-3.jpg\">\n",
    "\n",
    "This observation is then added to the prompt as additional context. It functions as real-world feedback, confirming whether the action succeeded and providing the needed details.\n",
    "\n",
    "**Updated thought**\n",
    "\n",
    "**Reflecting**\n",
    "\n",
    "With the observation in hand, Alfred updates its internal reasoning. \n",
    "\n",
    "\"*`Now that i have the weather data for New york, Ican compile an answer for the user.`*\"\n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/alfred-agent-4.jpg\">\n",
    "\n",
    "**Final Action**\n",
    "\n",
    "Alfred then generates a final response formatted as we it to:\n",
    "\n",
    "**Thought**: I have the weather data now. The current weather in New York is partly cloudy with temperature of 15°C and 60% humidity.\n",
    "\n",
    "**Final Answer**: The current weather in New York is partly cloudy with temperature of 15°C and 60% humidity.\n",
    "\n",
    "This final action sends the answer back to the user, closing the loop. \n",
    "\n",
    "<img src=\"https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit1/alfred-agent-5.jpg\">\n",
    "\n",
    "What we see in this example: \n",
    "\n",
    "- **Agent iteract through a loop untill the objective is fulfilled**:\n",
    "\n",
    "**Alfred's process is cyclical**. It starts with thought, then act by calling a tool, and finally observes the outcome. If the observation and indicated an error or incomplete data, Alfred could have re-entered the cycle to correct its approach. \n",
    "\n",
    "- **Tool Integration**:\n",
    "\n",
    "The ability to call a tool (like a weather API) enables Alfred to go **beyond static knowledge and retrieve real-time data**, an essential aspect of many AI Agents. \n",
    "\n",
    "- **Dynamic Apdaptation**: \n",
    "\n",
    "Each cycle allows the agent to incorporate fresh information (observation) into its reasoning (thought), ensuring that the final answer well-informed and accurate. \n",
    "\n",
    "This example showcasesthe core concepts behid the *`ReAct cycle`* (a concept we're going to develop in the next section): **the interplay of Thought, Action, and ibservation empowers AI Agent to solve complex rasks iteratively**. \n",
    "\n",
    "by understanding and applying these principles, you can design agent that not only reason about their tasks but also **effectively utilize external tools to complete them**, all while continuously refining their output based on environmental feedback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbf2d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40eabb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61468f88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d91c26a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
